{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d86a6d-5ea3-4707-bd7e-c4fe34df5e15",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "The work in this notebook focuses on the problem formulation and model selection, training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920deb72-cff9-4bff-9509-550ae57aae0a",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "\n",
    "In this section I work out the sliding window and prediction horizon. Since I couldn't find any mentions of recording frequency for this dataset, I will work with the assumption that the data is recorded in 1-minute intervals. The exact unknown time interval is not critical, this interpretation mainly improves readability of the experiment.\n",
    "\n",
    "Because we work with multiple machines, all processing is done per machine first and only then the resulting samples are combined. This avoids mixing timelines and prevents look-ahead leakage from overlapping windows around the split point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3facde0b-0bea-4014-9b62-4845de424be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b9baf7f-d52f-4946-b04f-cbfd1d5d02b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded machines: 8\n",
      "Names: ['machine-1-1', 'machine-1-2', 'machine-1-3', 'machine-1-4', 'machine-1-5', 'machine-1-6', 'machine-1-7', 'machine-1-8']\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/processed/smd_group1\")\n",
    "\n",
    "csv_paths = sorted(DATA_DIR.glob(\"machine-1-*.csv\"))\n",
    "if not csv_paths:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No machine-1-*.csv files found under: {DATA_DIR.resolve()}\"\n",
    "    )\n",
    "\n",
    "machines = {}\n",
    "for p in csv_paths:\n",
    "    df = pd.read_csv(p)\n",
    "\n",
    "    if \"label\" not in df.columns:\n",
    "        raise ValueError(f\"Missing 'label' column in: {p.name}\")\n",
    "\n",
    "    # Ensure labels are ints (0/1)\n",
    "    df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "    machines[p.stem] = df\n",
    "\n",
    "print(f\"Loaded machines: {len(machines)}\")\n",
    "print(\"Names:\", list(machines.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f93dba-5a2f-4df7-a55f-77676ed664e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature count (expected): 36\n",
      "All machines have consistent feature columns.\n"
     ]
    }
   ],
   "source": [
    "# Verify consistent feature columns across machines\n",
    "feature_cols_per_machine = {\n",
    "    name: [c for c in df.columns if c != \"label\"] for name, df in machines.items()\n",
    "}\n",
    "\n",
    "first_machine = next(iter(machines.keys()))\n",
    "base_features = feature_cols_per_machine[first_machine]\n",
    "\n",
    "mismatched = {\n",
    "    name: cols\n",
    "    for name, cols in feature_cols_per_machine.items()\n",
    "    if cols != base_features\n",
    "}\n",
    "\n",
    "print(f\"Feature count (expected): {len(base_features)}\")\n",
    "if mismatched:\n",
    "    print(\"WARNING: Feature columns mismatch detected:\")\n",
    "    for name, cols in mismatched.items():\n",
    "        print(name, \"->\", len(cols))\n",
    "else:\n",
    "    print(\"All machines have consistent feature columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607ff04-c99a-4649-a520-eb387ccd0745",
   "metadata": {},
   "source": [
    "### Prediction Horizon H\n",
    "\n",
    "Determining the size of H presents a trade-off:\n",
    "- Large (e.g. 60 min): great for operators, because they get a lot of time to fix the issue, but prediction accuracy typically drops. Predicting a crash 1 hour in advance from minute-level metrics is very hard.\n",
    "- Small (e.g. 1 min): higher prediction accuracy, but operationally less useful. By the time the alert fires, the system may already be in a bad state.\n",
    "\n",
    "For this project, I set H = 5 minutes. This corresponds to a realistic reaction window and allows me to evaluate detection lead time in a meaningful way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b563be3-7130-4913-a4f0-1740011b8e1d",
   "metadata": {},
   "source": [
    "### Sliding Window W\n",
    "\n",
    "This parameter also presents a trade-off:\n",
    "\n",
    "- Small W (e.g. 1–2 min): the model mainly sees the current spike and cannot detect longer trends.\n",
    "- Large W (e.g. 60+ min): the model sees a lot of history, but the signal can be diluted with noise and irrelevant regime changes.\n",
    "\n",
    "Cloud infrastructure failures can appear abruptly (shock failures) or build up over 10–20 minutes. Selecting an exact value is not obvious, so I will compare two window sizes:\n",
    "\n",
    "- W = 12 minutes: captures short-term dynamics while remaining relatively noise-resistant.\n",
    "- W = 25 minutes: captures longer build-ups, but may include more irrelevant variation.\n",
    "\n",
    "Multi-machine processing:\n",
    "For each machine, I slide a window of size W over the timeline, compute rolling statistics (Mean, Std, Delta, Z-Score), and define the target label based on whether an incident occurs within the next H steps. Then, for each machine, I split samples chronologically into train/test using a gap of (W + H) steps around the split point to prevent overlap leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e50308bd-dad7-4006-8e90-ae13a74dd690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a single machine timeline into supervised samples\n",
    "def create_supervised_dataset(df: pd.DataFrame, window_size: int, horizon: int):\n",
    "    \n",
    "    if \"label\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'label' column in df\")\n",
    "\n",
    "    feature_df = df.drop(columns=[\"label\"])\n",
    "    labels = df[\"label\"].astype(int).to_numpy()\n",
    "    X_raw = feature_df.to_numpy()\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    t_end_list = []\n",
    "\n",
    "    for t in range(window_size, len(X_raw) - horizon):\n",
    "        window = X_raw[t - window_size : t]\n",
    "\n",
    "        w_mean = np.mean(window, axis=0)\n",
    "        w_std = np.std(window, axis=0)\n",
    "        w_delta = window[-1] - window[-2]\n",
    "\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            w_zscore = (window[-1] - w_mean) / w_std\n",
    "        w_zscore = np.nan_to_num(w_zscore, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        features_vector = np.concatenate([w_mean, w_std, w_delta, w_zscore])\n",
    "\n",
    "        future_window = labels[t : t + horizon]\n",
    "        incident_soon = 1 if future_window.sum() > 0 else 0\n",
    "\n",
    "        X_list.append(features_vector)\n",
    "        y_list.append(incident_soon)\n",
    "        t_end_list.append(t)\n",
    "\n",
    "    return np.array(X_list), np.array(y_list), np.array(t_end_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db343699-ea7c-4a2d-a38f-2a68332451ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pooled_train_test(\n",
    "    machines_dict: dict[str, pd.DataFrame],\n",
    "    window_size: int,\n",
    "    horizon: int,\n",
    "    train_frac: float = 0.70,\n",
    "):\n",
    "\n",
    "    gap = window_size + horizon\n",
    "\n",
    "    X_train_list, y_train_list = [], []\n",
    "    X_test_list, y_test_list = [], []\n",
    "\n",
    "    per_machine_stats = []\n",
    "\n",
    "    for name, df in machines_dict.items():\n",
    "        \n",
    "        # Create supervised windows\n",
    "        X, y, t_end = create_supervised_dataset(\n",
    "            df=df, window_size=window_size, horizon=horizon\n",
    "        )\n",
    "\n",
    "        # Split chronologically\n",
    "        split_t = int(len(df) * train_frac)\n",
    "\n",
    "        # Apply gap\n",
    "        train_mask = t_end < split_t\n",
    "        test_mask = t_end >= split_t + gap\n",
    "\n",
    "        X_train_m, y_train_m = X[train_mask], y[train_mask]\n",
    "        X_test_m, y_test_m = X[test_mask], y[test_mask]\n",
    "\n",
    "        if len(X_train_m) == 0 or len(X_test_m) == 0:\n",
    "            raise ValueError(\n",
    "                f\"Empty split for {name} (W={window_size}, H={horizon}). \"\n",
    "                f\"Try adjusting train_frac or verify series length.\"\n",
    "            )\n",
    "\n",
    "        X_train_list.append(X_train_m)\n",
    "        y_train_list.append(y_train_m)\n",
    "        X_test_list.append(X_test_m)\n",
    "        y_test_list.append(y_test_m)\n",
    "\n",
    "        per_machine_stats.append(\n",
    "            {\n",
    "                \"machine\": name,\n",
    "                \"train_windows\": int(len(y_train_m)),\n",
    "                \"train_pos_rate\": float(y_train_m.mean()),\n",
    "                \"test_windows\": int(len(y_test_m)),\n",
    "                \"test_pos_rate\": float(y_test_m.mean()),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Pool all train and test windows\n",
    "    X_train = np.concatenate(X_train_list, axis=0)\n",
    "    y_train = np.concatenate(y_train_list, axis=0)\n",
    "    X_test = np.concatenate(X_test_list, axis=0)\n",
    "    y_test = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "    stats_df = pd.DataFrame(per_machine_stats).sort_values(\"machine\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215fb121-66ba-4f6d-9996-267c4e92ce54",
   "metadata": {},
   "source": [
    "Next, I create the two proposed datasets with the two values for W. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a61043c3-09dd-4b9f-8289-41914b53f5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating pooled train/test sets (per-machine split with gap) ---\n",
      "\n",
      "[W=12, H=5]\n",
      "\n",
      "[W=25, H=5]\n",
      "\n",
      "--- Shape Verification ---\n",
      "Short Window (W=12): X_train=(135962, 144), X_test=(58140, 144)\n",
      "Long Window  (W=25): X_train=(135858, 144), X_test=(58036, 144)\n",
      "\n",
      "--- Class Balance post-windowing ---\n",
      "W=12: train_pos_rate=0.0518, test_pos_rate=0.0883\n",
      "W=25: train_pos_rate=0.0518, test_pos_rate=0.0883\n",
      "\n",
      "--- Per-machine window stats (W=12) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine</th>\n",
       "      <th>train_windows</th>\n",
       "      <th>train_pos_rate</th>\n",
       "      <th>test_windows</th>\n",
       "      <th>test_pos_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine-1-1</td>\n",
       "      <td>19923</td>\n",
       "      <td>0.107464</td>\n",
       "      <td>8522</td>\n",
       "      <td>0.066651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>machine-1-2</td>\n",
       "      <td>16573</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>7087</td>\n",
       "      <td>0.042613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine-1-3</td>\n",
       "      <td>16580</td>\n",
       "      <td>0.027744</td>\n",
       "      <td>7089</td>\n",
       "      <td>0.057131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine-1-4</td>\n",
       "      <td>16582</td>\n",
       "      <td>0.024665</td>\n",
       "      <td>7091</td>\n",
       "      <td>0.050628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine-1-5</td>\n",
       "      <td>16582</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>7090</td>\n",
       "      <td>0.003385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>machine-1-6</td>\n",
       "      <td>16570</td>\n",
       "      <td>0.037236</td>\n",
       "      <td>7085</td>\n",
       "      <td>0.453211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>machine-1-7</td>\n",
       "      <td>16575</td>\n",
       "      <td>0.142504</td>\n",
       "      <td>7088</td>\n",
       "      <td>0.012415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>machine-1-8</td>\n",
       "      <td>16577</td>\n",
       "      <td>0.040116</td>\n",
       "      <td>7088</td>\n",
       "      <td>0.025113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       machine  train_windows  train_pos_rate  test_windows  test_pos_rate\n",
       "0  machine-1-1          19923        0.107464          8522       0.066651\n",
       "1  machine-1-2          16573        0.016895          7087       0.042613\n",
       "2  machine-1-3          16580        0.027744          7089       0.057131\n",
       "3  machine-1-4          16582        0.024665          7091       0.050628\n",
       "4  machine-1-5          16582        0.006272          7090       0.003385\n",
       "5  machine-1-6          16570        0.037236          7085       0.453211\n",
       "6  machine-1-7          16575        0.142504          7088       0.012415\n",
       "7  machine-1-8          16577        0.040116          7088       0.025113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Per-machine window stats (W=25) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine</th>\n",
       "      <th>train_windows</th>\n",
       "      <th>train_pos_rate</th>\n",
       "      <th>test_windows</th>\n",
       "      <th>test_pos_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine-1-1</td>\n",
       "      <td>19910</td>\n",
       "      <td>0.107534</td>\n",
       "      <td>8509</td>\n",
       "      <td>0.065225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>machine-1-2</td>\n",
       "      <td>16560</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>7074</td>\n",
       "      <td>0.042692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine-1-3</td>\n",
       "      <td>16567</td>\n",
       "      <td>0.027766</td>\n",
       "      <td>7076</td>\n",
       "      <td>0.057236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine-1-4</td>\n",
       "      <td>16569</td>\n",
       "      <td>0.024685</td>\n",
       "      <td>7078</td>\n",
       "      <td>0.050721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine-1-5</td>\n",
       "      <td>16569</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>7077</td>\n",
       "      <td>0.003391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>machine-1-6</td>\n",
       "      <td>16557</td>\n",
       "      <td>0.037265</td>\n",
       "      <td>7072</td>\n",
       "      <td>0.454044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>machine-1-7</td>\n",
       "      <td>16562</td>\n",
       "      <td>0.142616</td>\n",
       "      <td>7075</td>\n",
       "      <td>0.012438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>machine-1-8</td>\n",
       "      <td>16564</td>\n",
       "      <td>0.040147</td>\n",
       "      <td>7075</td>\n",
       "      <td>0.025159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       machine  train_windows  train_pos_rate  test_windows  test_pos_rate\n",
       "0  machine-1-1          19910        0.107534          8509       0.065225\n",
       "1  machine-1-2          16560        0.016908          7074       0.042692\n",
       "2  machine-1-3          16567        0.027766          7076       0.057236\n",
       "3  machine-1-4          16569        0.024685          7078       0.050721\n",
       "4  machine-1-5          16569        0.006277          7077       0.003391\n",
       "5  machine-1-6          16557        0.037265          7072       0.454044\n",
       "6  machine-1-7          16562        0.142616          7075       0.012438\n",
       "7  machine-1-8          16564        0.040147          7075       0.025159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "H = 5\n",
    "W_short = 12\n",
    "W_long = 25\n",
    "\n",
    "print(\"--- Creating pooled train/test sets (per-machine split with gap) ---\")\n",
    "\n",
    "print(f\"\\n[W={W_short}, H={H}]\")\n",
    "X_train_short, y_train_short, X_test_short, y_test_short, stats_short = (\n",
    "    build_pooled_train_test(\n",
    "        machines_dict=machines,\n",
    "        window_size=W_short,\n",
    "        horizon=H,\n",
    "        train_frac=0.70,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"\\n[W={W_long}, H={H}]\")\n",
    "X_train_long, y_train_long, X_test_long, y_test_long, stats_long = build_pooled_train_test(\n",
    "    machines_dict=machines,\n",
    "    window_size=W_long,\n",
    "    horizon=H,\n",
    "    train_frac=0.70,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Shape Verification ---\")\n",
    "print(f\"Short Window (W=12): X_train={X_train_short.shape}, X_test={X_test_short.shape}\")\n",
    "print(f\"Long Window  (W=25): X_train={X_train_long.shape}, X_test={X_test_long.shape}\")\n",
    "\n",
    "print(\"\\n--- Class Balance post-windowing ---\")\n",
    "print(\n",
    "    f\"W=12: train_pos_rate={y_train_short.mean():.4f}, \"\n",
    "    f\"test_pos_rate={y_test_short.mean():.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"W=25: train_pos_rate={y_train_long.mean():.4f}, \"\n",
    "    f\"test_pos_rate={y_test_long.mean():.4f}\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Per-machine window stats (W=12) ---\")\n",
    "display(stats_short)\n",
    "\n",
    "print(\"\\n--- Per-machine window stats (W=25) ---\")\n",
    "display(stats_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4276bf7-e3a1-4bfe-a0a7-e36469cc3d68",
   "metadata": {},
   "source": [
    "## Model Selection and Training\n",
    "\n",
    "Based on information observed during EDA as well as the nature of the problem, I have chosen a\n",
    "Random Forest Classifier for this task.\n",
    "\n",
    "The model will be trained on pooled sliding-window samples generated from all machines in SMD Group 1,\n",
    "using a per-machine chronological split with a gap to prevent overlap leakage. This setup\n",
    "matches the intended production workflow: the model is trained on historical data and evaluated on\n",
    "strictly future time windows.\n",
    "\n",
    "The main reasons for selecting Random Forest are:\n",
    "\n",
    "1. **Non-Linear features:** In the bivariate analysis, I observed that some metrics are sparse / event-driven and spike during incidents. Linear models (e.g. Logistic Regression) struggle with such sharp thresholds, while decision trees capture them naturally.\n",
    "2. **Interaction Effects:** Some features (like feat_15 or feat_22) appeared stable but are likely informative in combination. Random Forests can learn these interactions without manual feature engineering.\n",
    "3. **Robustness to Noise:** Cloud metrics are noisy and non-stationary. By averaging the predictions of multiple trees, the Random Forest reduces the variance and is less likely to overfit to individual noisy data points compared to a single Decision Tree.\n",
    "4. **Efficiency for Retraining:** The project description requires a system capable of periodic retraining. Random Forests train quickly, parallelize well, and are feasible for periodic retraining in a lightweight deployment setup.\n",
    "\n",
    "\n",
    "### Training Strategy\n",
    "\n",
    "I will train two separate models to compare the impact of the window size:\n",
    "1. Model A: Trained on \\(W=12\\)\n",
    "2. Model B: Trained on \\(W=25\\)\n",
    "\n",
    "After converting the series into supervised sliding-window samples, the resulting class balance is imbalanced and can vary by machine. To ensure the model focuses on capturing incidents (Recall) rather than maximizing accuracy, I'll use `class_weight=\"balanced\"` or `\"balanced_subsample\"`. This penalizes missed incidents more than false alarms.\n",
    "\n",
    "To prevent look-ahead leakage, all splits are chronological per machine and include a purge gap of (W + H) around the split point.\n",
    "\n",
    "Goal: Following the project description, I target approximately 80% recall with respect to existing incident-triggering alerts on a held-out evaluation period. The alert threshold will be selected on a validation period and then fixed for the final evaluation.\n",
    "\n",
    "### Hyperparameter Tuning Strategy - Randomized Search\n",
    "\n",
    "Because sliding-window samples overlap heavily in time, many training rows are near-duplicates. This increases the risk that a high-capacity model memorizes recurring patterns instead of actual pre-incident signals. Additionally, metric behavior can shift over time, so regularization and robustness matter more than marginal in-sample accuracy.\n",
    "\n",
    "Instead of an exhaustive grid search, I will use Randomized Search over a carefully chosen parameter\n",
    "space. Randomized search is more compute-efficient and typically finds strong configurations with\n",
    "fewer fits, especially when only a subset of hyperparameters strongly influences performance.\n",
    "\n",
    "I tune the following parameters (highest impact first):\n",
    "\n",
    "- **min_samples_leaf:** Increases the minimum support required for a decision rule. This is a key regularizer for overlapping windows and noisy spikes. Larger values reduce overfitting and improve stability.\n",
    "- **max_depth:** Limits tree complexity. Prevents very deep trees from learning too specific rules that do not generalize to future periods or other machines.\n",
    "- **max_features:** Controls how many features are considered at each split. Lower values decorrelate trees and generally improve generalization in noisy settings.\n",
    "- **max_samples (with bootstrap=True):** Subsamples training rows for each tree, reducing correlation between trees and improving robustness. Useful when training data contains many overlapping windows.\n",
    "- **n_estimators:** Controls ensemble size. More trees reduce variance and stabilize probabilities at the cost of training time. I search over moderate-to-high values.\n",
    "- **class_weight:** Incident-imminent samples are rare after windowing. class_weight=\"balanced_subsample\" adjusts the class weighting per tree bootstrap sample and helps the model pay attention to positives.\n",
    "\n",
    "Tuning protocol:\n",
    "- Splits are chronological per machine and include a purge gap of (W + H) steps to avoid overlap\n",
    "  leakage across split boundaries.\n",
    "- Hyperparameters are selected using a time-consistent validation set (future relative to the\n",
    "  sub-train period).\n",
    "- The tuning score is Average Precision (PR-AUC), which is suitable for imbalanced classification.\n",
    "  The final alert threshold selection (to target ~80% recall) is handled later during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afbe4ae9-3bf6-4fe4-9cef-66eb0da897b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32cacc54-8543-4120-8b5d-4b71a4f33e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pooled_train_val_test(\n",
    "    machines_dict: dict[str, pd.DataFrame],\n",
    "    window_size: int,\n",
    "    horizon: int,\n",
    "    train_frac: float = 0.70,\n",
    "    val_frac_within_train: float = 0.20,\n",
    "    dtype=np.float32,\n",
    "):\n",
    "    gap = window_size + horizon\n",
    "\n",
    "    X_tr_list, y_tr_list = [], []\n",
    "    X_val_list, y_val_list = [], []\n",
    "    X_te_list, y_te_list = [], []\n",
    "\n",
    "    stats = []\n",
    "\n",
    "    for name, df in machines_dict.items():\n",
    "        X, y, t_end = create_supervised_dataset(\n",
    "            df=df, window_size=window_size, horizon=horizon\n",
    "        )\n",
    "\n",
    "        n = len(df)\n",
    "        cut_train_end = int(n * train_frac)\n",
    "        cut_val_start = int(cut_train_end * (1 - val_frac_within_train))\n",
    "\n",
    "        tr_mask = t_end < cut_val_start\n",
    "        val_mask = (t_end >= cut_val_start + gap) & (t_end < cut_train_end)\n",
    "        te_mask = t_end >= cut_train_end + gap\n",
    "\n",
    "        X_tr_m, y_tr_m = X[tr_mask], y[tr_mask]\n",
    "        X_val_m, y_val_m = X[val_mask], y[val_mask]\n",
    "        X_te_m, y_te_m = X[te_mask], y[te_mask]\n",
    "\n",
    "        if len(X_tr_m) == 0 or len(X_val_m) == 0 or len(X_te_m) == 0:\n",
    "            raise ValueError(\n",
    "                f\"Empty split for {name}. \"\n",
    "                f\"W={window_size}, H={horizon}, \"\n",
    "                f\"len(tr)={len(X_tr_m)}, len(val)={len(X_val_m)}, len(te)={len(X_te_m)}. \"\n",
    "                \"Adjust fractions or verify series length.\"\n",
    "            )\n",
    "\n",
    "        X_tr_list.append(X_tr_m.astype(dtype, copy=False))\n",
    "        y_tr_list.append(y_tr_m.astype(np.int8, copy=False))\n",
    "        X_val_list.append(X_val_m.astype(dtype, copy=False))\n",
    "        y_val_list.append(y_val_m.astype(np.int8, copy=False))\n",
    "        X_te_list.append(X_te_m.astype(dtype, copy=False))\n",
    "        y_te_list.append(y_te_m.astype(np.int8, copy=False))\n",
    "\n",
    "        stats.append(\n",
    "            {\n",
    "                \"machine\": name,\n",
    "                \"train_windows\": int(len(y_tr_m)),\n",
    "                \"train_pos_rate\": float(y_tr_m.mean()),\n",
    "                \"val_windows\": int(len(y_val_m)),\n",
    "                \"val_pos_rate\": float(y_val_m.mean()),\n",
    "                \"test_windows\": int(len(y_te_m)),\n",
    "                \"test_pos_rate\": float(y_te_m.mean()),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0)\n",
    "    y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0)\n",
    "    y_val = np.concatenate(y_val_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0)\n",
    "    y_te = np.concatenate(y_te_list, axis=0)\n",
    "\n",
    "    stats_df = pd.DataFrame(stats).sort_values(\"machine\").reset_index(drop=True)\n",
    "    return X_tr, y_tr, X_val, y_val, X_te, y_te, stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d82ec-065a-4b79-9d54-4488db51d911",
   "metadata": {},
   "source": [
    "For each machine timeline, this function:\n",
    "- Creates supervised windows\n",
    "- Splits into sub-train / validation parts within the training period\n",
    "- Splits into test on the held-out future period\n",
    "- Applies a purge gap W+H around split points to prevent overlap leakage\n",
    "- Returns pooled arrays across machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a83072d-044d-4ca7-82ba-dbb7673e1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_search_rf(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    param_distributions: dict,\n",
    "    n_iter: int = 40,\n",
    "    random_state: int = 42,\n",
    "    n_jobs: int = -1,\n",
    "    verbose: int = 1,\n",
    "):\n",
    "    sampler = ParameterSampler(\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    history = []\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    for i, params in enumerate(sampler, start=1):\n",
    "        model = RandomForestClassifier(\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs,\n",
    "            **params,\n",
    "        )\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        proba = model.predict_proba(X_val)[:, 1]\n",
    "        ap = average_precision_score(y_val, proba)\n",
    "\n",
    "        row = {\"iter\": i, \"avg_precision\": float(ap), **params}\n",
    "        history.append(row)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[{i:02d}/{n_iter}] AP={ap:.5f} params={params}\")\n",
    "\n",
    "        if ap > best_score:\n",
    "            best_score = ap\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "    history_df = pd.DataFrame(history).sort_values(\n",
    "        \"avg_precision\", ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return best_model, best_params, history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ff78e-795f-4d20-8145-a801df0ab18e",
   "metadata": {},
   "source": [
    "This function implements randomized search for sample hyperparameters and scores on (X_val, y_val) using Average Precision (PR-AUC). At the end, it returns the best_estimator, best_params and history_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33db9790-bf81-471a-ab90-8dbd3d4af7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 6, 10, 14, 18],\n",
    "    \"min_samples_leaf\": [5, 10, 20],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"max_features\": [\"sqrt\", 0.3, 0.5, 0.7],\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_samples\": [0.5, 0.7, 0.9, 1.0],\n",
    "    \"class_weight\": [\"balanced_subsample\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11992f1a-4ccf-4e00-9c6b-2435c0caec23",
   "metadata": {},
   "source": [
    "This is the hyperparameter space to search based on definition above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e2c794f-da9d-40bb-ba33-698c842ceae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- W=12 --------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "n_estimators\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>14</td>\n",
       "      <td>0.598027</td>\n",
       "      <td>0.602285</td>\n",
       "      <td>0.030357</td>\n",
       "      <td>0.647160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>14</td>\n",
       "      <td>0.575987</td>\n",
       "      <td>0.590493</td>\n",
       "      <td>0.069536</td>\n",
       "      <td>0.616955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12</td>\n",
       "      <td>0.568338</td>\n",
       "      <td>0.582558</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>0.610600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean    median       std       max\n",
       "n_estimators                                               \n",
       "100              14  0.598027  0.602285  0.030357  0.647160\n",
       "200              14  0.575987  0.590493  0.069536  0.616955\n",
       "300              12  0.568338  0.582558  0.045549  0.610600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "max_depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.612496</td>\n",
       "      <td>0.610134</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.647160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.596977</td>\n",
       "      <td>0.592612</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>0.623512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.563542</td>\n",
       "      <td>0.573758</td>\n",
       "      <td>0.048704</td>\n",
       "      <td>0.616955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.511147</td>\n",
       "      <td>0.545033</td>\n",
       "      <td>0.084495</td>\n",
       "      <td>0.555844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean    median       std       max\n",
       "max_depth                                               \n",
       "14.0           8  0.612496  0.610134  0.019480  0.647160\n",
       "18.0          10  0.596977  0.592612  0.016045  0.623512\n",
       "10.0           8  0.563542  0.573758  0.048704  0.616955\n",
       "6.0            6  0.511147  0.545033  0.084495  0.555844"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "min_samples_leaf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>0.600717</td>\n",
       "      <td>0.595033</td>\n",
       "      <td>0.014180</td>\n",
       "      <td>0.620026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18</td>\n",
       "      <td>0.580415</td>\n",
       "      <td>0.604257</td>\n",
       "      <td>0.068891</td>\n",
       "      <td>0.647160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.573584</td>\n",
       "      <td>0.582986</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>0.614967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count      mean    median       std       max\n",
       "min_samples_leaf                                               \n",
       "10                    7  0.600717  0.595033  0.014180  0.620026\n",
       "20                   18  0.580415  0.604257  0.068891  0.647160\n",
       "5                    15  0.573584  0.582986  0.036404  0.614967"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "min_samples_split\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_samples_split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16</td>\n",
       "      <td>0.590983</td>\n",
       "      <td>0.598336</td>\n",
       "      <td>0.036053</td>\n",
       "      <td>0.647160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>0.578883</td>\n",
       "      <td>0.584430</td>\n",
       "      <td>0.034851</td>\n",
       "      <td>0.620026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.570456</td>\n",
       "      <td>0.594232</td>\n",
       "      <td>0.081881</td>\n",
       "      <td>0.630634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count      mean    median       std       max\n",
       "min_samples_split                                               \n",
       "20                    16  0.590983  0.598336  0.036053  0.647160\n",
       "5                     13  0.578883  0.584430  0.034851  0.620026\n",
       "10                    11  0.570456  0.594232  0.081881  0.630634"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "max_features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>13</td>\n",
       "      <td>0.596011</td>\n",
       "      <td>0.597728</td>\n",
       "      <td>0.027010</td>\n",
       "      <td>0.630634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.595004</td>\n",
       "      <td>0.606647</td>\n",
       "      <td>0.032939</td>\n",
       "      <td>0.647160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.587430</td>\n",
       "      <td>0.594232</td>\n",
       "      <td>0.022179</td>\n",
       "      <td>0.609668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqrt</th>\n",
       "      <td>7</td>\n",
       "      <td>0.525169</td>\n",
       "      <td>0.582986</td>\n",
       "      <td>0.094142</td>\n",
       "      <td>0.595033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean    median       std       max\n",
       "max_features                                               \n",
       "0.7              13  0.596011  0.597728  0.027010  0.630634\n",
       "0.3              11  0.595004  0.606647  0.032939  0.647160\n",
       "0.5               9  0.587430  0.594232  0.022179  0.609668\n",
       "sqrt              7  0.525169  0.582986  0.094142  0.595033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "max_samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_samples</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.601280</td>\n",
       "      <td>0.606647</td>\n",
       "      <td>0.026409</td>\n",
       "      <td>0.630634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>12</td>\n",
       "      <td>0.590555</td>\n",
       "      <td>0.594116</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.647160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.572855</td>\n",
       "      <td>0.578661</td>\n",
       "      <td>0.029765</td>\n",
       "      <td>0.605583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>7</td>\n",
       "      <td>0.546707</td>\n",
       "      <td>0.594232</td>\n",
       "      <td>0.101771</td>\n",
       "      <td>0.609922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean    median       std       max\n",
       "max_samples                                               \n",
       "0.5             11  0.601280  0.606647  0.026409  0.630634\n",
       "0.7             12  0.590555  0.594116  0.033557  0.647160\n",
       "1.0             10  0.572855  0.578661  0.029765  0.605583\n",
       "0.9              7  0.546707  0.594232  0.101771  0.609922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- W=25 --------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "n_estimators\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>14</td>\n",
       "      <td>0.622710</td>\n",
       "      <td>0.629508</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.659363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12</td>\n",
       "      <td>0.613016</td>\n",
       "      <td>0.623008</td>\n",
       "      <td>0.060262</td>\n",
       "      <td>0.674736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>14</td>\n",
       "      <td>0.611082</td>\n",
       "      <td>0.639933</td>\n",
       "      <td>0.086925</td>\n",
       "      <td>0.663072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean    median       std       max\n",
       "n_estimators                                               \n",
       "100              14  0.622710  0.629508  0.030051  0.659363\n",
       "300              12  0.613016  0.623008  0.060262  0.674736\n",
       "200              14  0.611082  0.639933  0.086925  0.663072"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "max_depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.645495</td>\n",
       "      <td>0.651350</td>\n",
       "      <td>0.017974</td>\n",
       "      <td>0.662127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.632211</td>\n",
       "      <td>0.636028</td>\n",
       "      <td>0.026369</td>\n",
       "      <td>0.662597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.597918</td>\n",
       "      <td>0.623941</td>\n",
       "      <td>0.067574</td>\n",
       "      <td>0.663072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.553292</td>\n",
       "      <td>0.597773</td>\n",
       "      <td>0.114656</td>\n",
       "      <td>0.617617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean    median       std       max\n",
       "max_depth                                               \n",
       "14.0           8  0.645495  0.651350  0.017974  0.662127\n",
       "18.0          10  0.632211  0.636028  0.026369  0.662597\n",
       "10.0           8  0.597918  0.623941  0.067574  0.663072\n",
       "6.0            6  0.553292  0.597773  0.114656  0.617617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "min_samples_leaf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>0.639121</td>\n",
       "      <td>0.641052</td>\n",
       "      <td>0.031304</td>\n",
       "      <td>0.663072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.612432</td>\n",
       "      <td>0.619557</td>\n",
       "      <td>0.047134</td>\n",
       "      <td>0.662597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18</td>\n",
       "      <td>0.609386</td>\n",
       "      <td>0.628588</td>\n",
       "      <td>0.080179</td>\n",
       "      <td>0.674736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count      mean    median       std       max\n",
       "min_samples_leaf                                               \n",
       "10                    7  0.639121  0.641052  0.031304  0.663072\n",
       "5                    15  0.612432  0.619557  0.047134  0.662597\n",
       "20                   18  0.609386  0.628588  0.080179  0.674736"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "min_samples_split\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_samples_split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16</td>\n",
       "      <td>0.626048</td>\n",
       "      <td>0.640494</td>\n",
       "      <td>0.049562</td>\n",
       "      <td>0.674736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>0.609928</td>\n",
       "      <td>0.614767</td>\n",
       "      <td>0.040132</td>\n",
       "      <td>0.653128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.607586</td>\n",
       "      <td>0.628399</td>\n",
       "      <td>0.095887</td>\n",
       "      <td>0.662597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count      mean    median       std       max\n",
       "min_samples_split                                               \n",
       "20                    16  0.626048  0.640494  0.049562  0.674736\n",
       "5                     13  0.609928  0.614767  0.040132  0.653128\n",
       "10                    11  0.607586  0.628399  0.095887  0.662597"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "max_features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>13</td>\n",
       "      <td>0.652533</td>\n",
       "      <td>0.655560</td>\n",
       "      <td>0.014167</td>\n",
       "      <td>0.674736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.636567</td>\n",
       "      <td>0.639936</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.662597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.613816</td>\n",
       "      <td>0.619557</td>\n",
       "      <td>0.022879</td>\n",
       "      <td>0.641052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqrt</th>\n",
       "      <td>7</td>\n",
       "      <td>0.523609</td>\n",
       "      <td>0.574158</td>\n",
       "      <td>0.100155</td>\n",
       "      <td>0.602595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean    median       std       max\n",
       "max_features                                               \n",
       "0.7              13  0.652533  0.655560  0.014167  0.674736\n",
       "0.5               9  0.636567  0.639936  0.016578  0.662597\n",
       "0.3              11  0.613816  0.619557  0.022879  0.641052\n",
       "sqrt              7  0.523609  0.574158  0.100155  0.602595"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "max_samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_samples</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.636534</td>\n",
       "      <td>0.641052</td>\n",
       "      <td>0.027229</td>\n",
       "      <td>0.674736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>12</td>\n",
       "      <td>0.621983</td>\n",
       "      <td>0.624154</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.653128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.615912</td>\n",
       "      <td>0.628362</td>\n",
       "      <td>0.047631</td>\n",
       "      <td>0.662127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>7</td>\n",
       "      <td>0.572069</td>\n",
       "      <td>0.628777</td>\n",
       "      <td>0.127496</td>\n",
       "      <td>0.662597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean    median       std       max\n",
       "max_samples                                               \n",
       "0.5             11  0.636534  0.641052  0.027229  0.674736\n",
       "0.7             12  0.621983  0.624154  0.025313  0.653128\n",
       "1.0             10  0.615912  0.628362  0.047631  0.662127\n",
       "0.9              7  0.572069  0.628777  0.127496  0.662597"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extensive search that runs for a long time, for a demo, lower the n_iter parameter to 2-5\n",
    "\n",
    "# OUT_DIR = Path(\"../artifacts/rf_random_search_group1\")\n",
    "# OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# H = 5\n",
    "# W_values = [12, 25]\n",
    "\n",
    "# results = {}\n",
    "\n",
    "# for W in W_values:\n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(f\"TUNING RANDOM FOREST | W={W}, H={H}\")\n",
    "#     print(\"=\" * 80)\n",
    "\n",
    "#     X_tr, y_tr, X_val, y_val, X_te, y_te, stats_df = build_pooled_train_val_test(\n",
    "#         machines_dict=machines,\n",
    "#         window_size=W,\n",
    "#         horizon=H,\n",
    "#         train_frac=0.70,\n",
    "#         val_frac_within_train=0.20,\n",
    "#     )\n",
    "\n",
    "#     print(\"\\nSplit summary (per machine):\")\n",
    "#     display(stats_df)\n",
    "\n",
    "#     print(\"\\nPooled shapes:\")\n",
    "#     print(f\"X_tr={X_tr.shape}, y_tr_pos_rate={y_tr.mean():.4f}\")\n",
    "#     print(f\"X_val={X_val.shape}, y_val_pos_rate={y_val.mean():.4f}\")\n",
    "#     print(f\"X_te={X_te.shape}, y_te_pos_rate={y_te.mean():.4f}  (kept for later)\")\n",
    "\n",
    "#     best_model, best_params, hist_df = randomized_search_rf(\n",
    "#         X_tr=X_tr,\n",
    "#         y_tr=y_tr,\n",
    "#         X_val=X_val,\n",
    "#         y_val=y_val,\n",
    "#         param_distributions=param_distributions,\n",
    "#         n_iter=40,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1,\n",
    "#         verbose=1,\n",
    "#     )\n",
    "\n",
    "#     print(\"\\nBest params:\")\n",
    "#     print(best_params)\n",
    "#     print(\"\\nBest validation AP (PR-AUC):\", hist_df.iloc[0][\"avg_precision\"])\n",
    "\n",
    "#     # Save search history + params + model\n",
    "#     hist_path = OUT_DIR / f\"search_history_W{W}_H{H}.csv\"\n",
    "#     hist_df.to_csv(hist_path, index=False)\n",
    "\n",
    "#     params_path = OUT_DIR / f\"best_params_W{W}_H{H}.json\"\n",
    "#     with open(params_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(best_params, f, indent=2)\n",
    "\n",
    "#     model_path = OUT_DIR / f\"best_model_W{W}_H{H}.joblib\"\n",
    "#     dump(best_model, model_path)\n",
    "\n",
    "#     results[W] = {\n",
    "#         \"best_params\": best_params,\n",
    "#         \"best_val_ap\": float(hist_df.iloc[0][\"avg_precision\"]),\n",
    "#         \"history_path\": str(hist_path),\n",
    "#         \"model_path\": str(model_path),\n",
    "#     }\n",
    "\n",
    "# results\n",
    "\n",
    "\n",
    "# I ran the search and saved the results\n",
    "# Instead of repeating the search above, load the saved search history and analyze results:\n",
    "def summarize_param_effects(hist_df: pd.DataFrame, params: list[str]):\n",
    "    out = {}\n",
    "    for p in params:\n",
    "        out[p] = (\n",
    "            hist_df.groupby(p)[\"avg_precision\"]\n",
    "            .agg([\"count\", \"mean\", \"median\", \"std\", \"max\"])\n",
    "            .sort_values(\"mean\", ascending=False)\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "params_to_check = [\n",
    "    \"n_estimators\",\n",
    "    \"max_depth\",\n",
    "    \"min_samples_leaf\",\n",
    "    \"min_samples_split\",\n",
    "    \"max_features\",\n",
    "    \"max_samples\",\n",
    "]\n",
    "\n",
    "hist_df_12 = pd.read_csv(\"../artifacts/rf_random_search_group1/search_history_W12_H5.csv\")\n",
    "hist_df_25 = pd.read_csv(\"../artifacts/rf_random_search_group1/search_history_W25_H5.csv\")\n",
    "\n",
    "\n",
    "summaries_12 = summarize_param_effects(hist_df_12, params_to_check)\n",
    "print(\"-------------------------------------------------- W=12 --------------------------------------------------\")\n",
    "for p, table in summaries_12.items():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(p)\n",
    "    display(table)\n",
    "\n",
    "\n",
    "summaries_25 = summarize_param_effects(hist_df_25, params_to_check)\n",
    "\n",
    "print(\"-------------------------------------------------- W=25 --------------------------------------------------\")\n",
    "for p, table in summaries_25.items():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(p)\n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655deae-3ca5-477b-842d-eb2dec01b0d0",
   "metadata": {},
   "source": [
    "### Random Search Findings \n",
    "\n",
    "I ran 40 iterations of the algorithm above on both W=12 and W=25. The search history as well as the best found models and their parameters can be found in the artifacts folder. Here are the key findings from this search:\n",
    "\n",
    "Across both window sizes, similar trends emerged:\n",
    "\n",
    "- Subsampling helps: max_samples=0.5 consistently achieved the best mean AP, while 0.9/1.0 tended to perform worse or be less stable. This matches the heavy overlap of sliding windows. Subsampling reduces redundancy per tree and improves ensemble diversity.\n",
    "\n",
    "- Shallow trees underfit: max_depth=6 (and often 10) produced the lowest AP. Deeper trees performed better, suggesting the model needs sufficient depth to represent enough conditional logic.\n",
    "\n",
    "- Feature subsampling matters: max_features=\"sqrt\" was consistently the worst option. Fractional values performed better. \n",
    "\n",
    "- Stronger regularization is generally better: min_samples_split=20 and min_samples_leaf=10–20 were consistently strong choices, while very small values (5) appeared frequently among weaker runs.\n",
    "\n",
    "\n",
    "Overall, W=25 achieved a slightly higher validation AP on average than W=12, suggesting that a longer lookback window captures additional pre-incident context for this dataset. To see if there is a statistically significant difference between the mean randomly sampled hyperparameter configurations for W=25 and W=12, I will next do a hypothesis test on the 40 AP values.\n",
    "\n",
    "*Note on overfitting:*\n",
    "\n",
    "Hyperparameters are selected on a time-consistent validation period, which reduces look-ahead bias. However, selecting the best configuration from many trials can still overfit to the validation period (“hyperparameter overfitting”). A more robust setup would evaluate candidates across multiple walk-forward validation splits or across held-out machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d255752-90f3-4a88-a983-1a1da519e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n12: 40 mean12: 0.5814060080922664 std12: 0.0516366819279887\n",
      "n25: 40 mean25: 0.615731863576408 std25: 0.062221127452515367\n",
      "mean diff (25-12): 0.034325855484141576\n",
      "Paired by identical hyperparameter samples: True\n",
      "\n",
      "Paired t-test (H1: mean25 > mean12)\n",
      "t = 7.237272080355264 p(one-sided) = 5.072294793991226e-09\n",
      "Effect size (Cohen's dz) = 1.144313191013389\n",
      "\n",
      "Permutation test (H1: mean25 > mean12)\n",
      "observed mean diff = 0.034325855484141576\n",
      "p(one-sided) = 0.0030599388012239755\n",
      "\n",
      "Decision at alpha = 0.05\n",
      "Reject H0 (perm test): True\n"
     ]
    }
   ],
   "source": [
    "hist_df_12 = pd.read_csv(\n",
    "    \"../artifacts/rf_random_search_group1/search_history_W12_H5.csv\"\n",
    ")\n",
    "hist_df_25 = pd.read_csv(\n",
    "    \"../artifacts/rf_random_search_group1/search_history_W25_H5.csv\"\n",
    ")\n",
    "\n",
    "ap12 = hist_df_12[\"avg_precision\"].to_numpy(dtype=float)\n",
    "ap25 = hist_df_25[\"avg_precision\"].to_numpy(dtype=float)\n",
    "\n",
    "print(\"n12:\", len(ap12), \"mean12:\", ap12.mean(), \"std12:\", ap12.std(ddof=1))\n",
    "print(\"n25:\", len(ap25), \"mean25:\", ap25.mean(), \"std25:\", ap25.std(ddof=1))\n",
    "print(\"mean diff (25-12):\", ap25.mean() - ap12.mean())\n",
    "\n",
    "# Check if the two random searches used the exact same sampled params per iteration.\n",
    "param_cols = [\n",
    "    \"n_estimators\",\n",
    "    \"max_depth\",\n",
    "    \"min_samples_leaf\",\n",
    "    \"min_samples_split\",\n",
    "    \"max_features\",\n",
    "    \"bootstrap\",\n",
    "    \"max_samples\",\n",
    "    \"class_weight\",\n",
    "]\n",
    "\n",
    "paired = False\n",
    "if all(c in hist_df_12.columns for c in param_cols) and all(\n",
    "    c in hist_df_25.columns for c in param_cols\n",
    "):\n",
    "    df12_params = hist_df_12.sort_values(\"iter\")[param_cols].reset_index(drop=True)\n",
    "    df25_params = hist_df_25.sort_values(\"iter\")[param_cols].reset_index(drop=True)\n",
    "    paired = df12_params.equals(df25_params)\n",
    "\n",
    "print(\"Paired by identical hyperparameter samples:\", paired)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# 1) Parametric test\n",
    "if paired:\n",
    "    # Paired t-test on per-iteration AP differences\n",
    "    ap12_sorted = hist_df_12.sort_values(\"iter\")[\"avg_precision\"].to_numpy(dtype=float)\n",
    "    ap25_sorted = hist_df_25.sort_values(\"iter\")[\"avg_precision\"].to_numpy(dtype=float)\n",
    "    diffs = ap25_sorted - ap12_sorted\n",
    "\n",
    "    # scipy doesn't always support alternative for ttest_rel on older versions,\n",
    "    # so compute one-sided p-value manually from two-sided\n",
    "    t_stat, p_two = stats.ttest_rel(ap25_sorted, ap12_sorted, nan_policy=\"raise\")\n",
    "    p_one = p_two / 2 if t_stat > 0 else 1 - (p_two / 2)\n",
    "\n",
    "    print(\"\\nPaired t-test (H1: mean25 > mean12)\")\n",
    "    print(\"t =\", t_stat, \"p(one-sided) =\", p_one)\n",
    "\n",
    "    # Effect size for paired differences: Cohen's dz\n",
    "    dz = diffs.mean() / diffs.std(ddof=1)\n",
    "    print(\"Effect size (Cohen's dz) =\", dz)\n",
    "else:\n",
    "    # Welch's t-test (unequal variances)\n",
    "    # Use alternative=\"greater\" if available, else manual one-sided conversion.\n",
    "    try:\n",
    "        res = stats.ttest_ind(ap25, ap12, equal_var=False, alternative=\"greater\")\n",
    "        t_stat, p_one = float(res.statistic), float(res.pvalue)\n",
    "    except TypeError:\n",
    "        t_stat, p_two = stats.ttest_ind(ap25, ap12, equal_var=False)\n",
    "        p_one = p_two / 2 if t_stat > 0 else 1 - (p_two / 2)\n",
    "\n",
    "    print(\"\\nWelch t-test (unpaired) (H1: mean25 > mean12)\")\n",
    "    print(\"t =\", t_stat, \"p(one-sided) =\", p_one)\n",
    "\n",
    "    # Effect size (Cohen's d with pooled SD; descriptive)\n",
    "    s12 = ap12.std(ddof=1)\n",
    "    s25 = ap25.std(ddof=1)\n",
    "    s_pooled = np.sqrt((s12**2 + s25**2) / 2)\n",
    "    d = (ap25.mean() - ap12.mean()) / s_pooled\n",
    "    print(\"Effect size (Cohen's d, descriptive) =\", d)\n",
    "\n",
    "# 2) Permutation test on mean difference (robust, minimal assumptions)\n",
    "rng = np.random.default_rng(2026)\n",
    "observed = ap25.mean() - ap12.mean()\n",
    "\n",
    "combined = np.concatenate([ap25, ap12])\n",
    "n25 = len(ap25)\n",
    "\n",
    "n_perm = 50_000\n",
    "count = 0\n",
    "for _ in range(n_perm):\n",
    "    rng.shuffle(combined)\n",
    "    perm_25 = combined[:n25]\n",
    "    perm_12 = combined[n25:]\n",
    "    perm_diff = perm_25.mean() - perm_12.mean()\n",
    "    if perm_diff >= observed:\n",
    "        count += 1\n",
    "\n",
    "p_perm = (count + 1) / (n_perm + 1)\n",
    "\n",
    "print(\"\\nPermutation test (H1: mean25 > mean12)\")\n",
    "print(\"observed mean diff =\", observed)\n",
    "print(\"p(one-sided) =\", p_perm)\n",
    "\n",
    "print(\"\\nDecision at alpha =\", alpha)\n",
    "print(\"Reject H0 (perm test):\", p_perm < alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647af0ab-a38e-4a61-acad-34261af07a6a",
   "metadata": {},
   "source": [
    "The two searches were paired: each iteration evaluated the same randomly sampled RF\n",
    "hyperparameters under both window sizes (only W differed). This allows a paired hypothesis test:\n",
    "\n",
    "- H0: mean(AP_W12) = mean(AP_W25)\n",
    "- H1: mean(AP_W25) > mean(AP_W12)\n",
    "\n",
    "Results (n=40 paired runs):\n",
    "- mean(AP_W12) = 0.5814 (std = 0.0516)\n",
    "- mean(AP_W25) = 0.6157 (std = 0.0622)\n",
    "- mean difference = +0.0343 AP in favor of W=25\n",
    "\n",
    "Paired t-test (one-sided): p = 5.07e-09\n",
    "Permutation test (one-sided): p = 0.00306\n",
    "Effect size (Cohen’s dz) = 1.14\n",
    "\n",
    "Conclusion: W=25 yields a statistically significant and practically meaningful improvement in\n",
    "validation AP over W=12. Therefore, moving forward, I will now focus on tuning for W=25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "460e5129-98e1-4a47-9173-24e33db8ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successive_halving_rf(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    param_distributions: dict,\n",
    "    n_candidates: int = 30,\n",
    "    n_estimators_schedule=(50, 150, 400),\n",
    "    keep_ratio: float = 1 / 3,\n",
    "    random_state: int = 42,\n",
    "    n_jobs: int = -1,\n",
    "):\n",
    "    sampler = ParameterSampler(\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_candidates,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    candidates = list(sampler)\n",
    "\n",
    "    all_rows = []\n",
    "    survivors = candidates\n",
    "\n",
    "    best_params = None\n",
    "    best_n_estimators = None\n",
    "    best_ap = float(\"-inf\")\n",
    "\n",
    "    drop_cols = {\"avg_precision\", \"stage\", \"n_estimators\"}\n",
    "\n",
    "    for stage, n_estimators in enumerate(n_estimators_schedule, start=1):\n",
    "        print(f\"Stage {stage}...\")\n",
    "        stage_rows = []\n",
    "\n",
    "        for i, params in enumerate(survivors, start=1):\n",
    "            print(f\"Fitting model {i}...\")\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=random_state,\n",
    "                n_jobs=n_jobs,\n",
    "                **params,\n",
    "            )\n",
    "            model.fit(X_tr, y_tr)\n",
    "            proba = model.predict_proba(X_val)[:, 1]\n",
    "            ap = average_precision_score(y_val, proba)\n",
    "\n",
    "            row = {\n",
    "                \"stage\": stage,\n",
    "                \"n_estimators\": n_estimators,\n",
    "                \"avg_precision\": float(ap),\n",
    "                **params,\n",
    "            }\n",
    "            stage_rows.append(row)\n",
    "\n",
    "        stage_rows_sorted = sorted(\n",
    "            stage_rows, key=lambda r: r[\"avg_precision\"], reverse=True\n",
    "        )\n",
    "\n",
    "        if stage_rows_sorted[0][\"avg_precision\"] > best_ap:\n",
    "            best_ap = float(stage_rows_sorted[0][\"avg_precision\"])\n",
    "            best_n_estimators = int(stage_rows_sorted[0][\"n_estimators\"])\n",
    "            best_params = {\n",
    "                k: v for k, v in stage_rows_sorted[0].items() if k not in drop_cols\n",
    "            }\n",
    "\n",
    "        stage_df = pd.DataFrame(stage_rows_sorted)\n",
    "        all_rows.append(stage_df)\n",
    "\n",
    "        k = max(1, math.ceil(len(stage_rows_sorted) * keep_ratio))\n",
    "        survivors = [\n",
    "            {kk: vv for kk, vv in r.items() if kk not in drop_cols}\n",
    "            for r in stage_rows_sorted[:k]\n",
    "        ]\n",
    "\n",
    "        print(\n",
    "            f\"Stage {stage}: n_estimators={n_estimators}, \"\n",
    "            f\"candidates={len(stage_rows_sorted)} -> keep={k}, \"\n",
    "            f\"best AP={stage_rows_sorted[0]['avg_precision']:.5f}\"\n",
    "        )\n",
    "\n",
    "    history_df = pd.concat(all_rows, axis=0, ignore_index=True)\n",
    "    return best_params, best_n_estimators, best_ap, history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6e9c281-e453-474b-8f84-ffe86b7b57d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>bootstrap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.668961</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.667434</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.664330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.663952</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.663724</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.662185</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.660921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.660824</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.659616</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.658833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stage  n_estimators  avg_precision  max_depth  min_samples_leaf  \\\n",
       "40      3           400       0.668961       14.0                10   \n",
       "41      3           400       0.667434       14.0                20   \n",
       "30      2           150       0.664330        NaN                20   \n",
       "31      2           150       0.663952       18.0                20   \n",
       "42      3           400       0.663724       18.0                20   \n",
       "32      2           150       0.662185       14.0                20   \n",
       "43      3           400       0.660921        NaN                20   \n",
       "0       1            50       0.660824       14.0                20   \n",
       "33      2           150       0.659616       14.0                10   \n",
       "1       1            50       0.658833        NaN                20   \n",
       "\n",
       "    min_samples_split  max_features  max_samples        class_weight  \\\n",
       "40                 20           0.7          0.5  balanced_subsample   \n",
       "41                 50           0.7          0.5  balanced_subsample   \n",
       "30                 50           0.7          0.5  balanced_subsample   \n",
       "31                 20           0.7          0.5  balanced_subsample   \n",
       "42                 20           0.7          0.5  balanced_subsample   \n",
       "32                 50           0.7          0.5  balanced_subsample   \n",
       "43                 50           0.7          0.5  balanced_subsample   \n",
       "0                  50           0.7          0.5  balanced_subsample   \n",
       "33                 20           0.7          0.5  balanced_subsample   \n",
       "1                  50           0.7          0.5  balanced_subsample   \n",
       "\n",
       "    bootstrap  \n",
       "40       True  \n",
       "41       True  \n",
       "30       True  \n",
       "31       True  \n",
       "42       True  \n",
       "32       True  \n",
       "43       True  \n",
       "0        True  \n",
       "33       True  \n",
       "1        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best AP by stage:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>best_avg_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.660824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.664330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.668961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stage  best_avg_precision\n",
       "0      1            0.660824\n",
       "1      2            0.664330\n",
       "2      3            0.668961"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Successive search implementation, takes a while to compute.\n",
    "\n",
    "# W = 25\n",
    "# H = 5\n",
    "\n",
    "# X_tr, y_tr, X_val, y_val, X_te, y_te, _ = build_pooled_train_val_test(\n",
    "#     machines_dict=machines,\n",
    "#     window_size=W,\n",
    "#     horizon=H,\n",
    "#     train_frac=0.70,\n",
    "#     val_frac_within_train=0.20,\n",
    "# )\n",
    "\n",
    "# param_space_w25 = {\n",
    "#     \"max_depth\": [14, 18, None],\n",
    "#     \"min_samples_leaf\": [10, 20],\n",
    "#     \"min_samples_split\": [20, 50, 100],\n",
    "#     \"max_features\": [0.5, 0.7],\n",
    "#     \"bootstrap\": [True],\n",
    "#     \"max_samples\": [0.5, 0.7],\n",
    "#     \"class_weight\": [\"balanced_subsample\"],\n",
    "# }\n",
    "\n",
    "# best_params, best_n_est, best_ap, sh_hist = successive_halving_rf(\n",
    "#     X_tr=X_tr,\n",
    "#     y_tr=y_tr,\n",
    "#     X_val=X_val,\n",
    "#     y_val=y_val,\n",
    "#     param_distributions=param_space_w25,\n",
    "#     n_candidates=30,\n",
    "#     n_estimators_schedule=(50, 150, 400),\n",
    "#     keep_ratio=1 / 3,\n",
    "#     random_state=2026,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "# print(\"\\nBest found:\")\n",
    "# print(\"AP:\", best_ap)\n",
    "# print(\"n_estimators:\", best_n_est)\n",
    "# print(\"params:\", best_params)\n",
    "\n",
    "# display(sh_hist.sort_values(\"avg_precision\", ascending=False).head(10))\n",
    "\n",
    "\n",
    "# I ran the search and saved the results\n",
    "# Instead of repeating the search above, load the saved search history and analyze results:\n",
    "\n",
    "def load_search_history(out_dir: str | Path, run_name: str) -> pd.DataFrame:\n",
    "    out_dir = Path(out_dir)\n",
    "    parquet_path = out_dir / f\"{run_name}.parquet\"\n",
    "    csv_path = out_dir / f\"{run_name}.csv\"\n",
    "\n",
    "    if parquet_path.exists():\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "    elif csv_path.exists():\n",
    "        df = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Missing {parquet_path} and {csv_path}\")\n",
    "\n",
    "    if \"max_depth\" in df.columns:\n",
    "        df[\"max_depth\"] = df[\"max_depth\"].where(\n",
    "            ~df[\"max_depth\"].isna(), other=None\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_top_results(history_df: pd.DataFrame, top_n: int = 10):\n",
    "    cols = [\n",
    "        c\n",
    "        for c in [\n",
    "            \"stage\",\n",
    "            \"n_estimators\",\n",
    "            \"avg_precision\",\n",
    "            \"max_depth\",\n",
    "            \"min_samples_leaf\",\n",
    "            \"min_samples_split\",\n",
    "            \"max_features\",\n",
    "            \"max_samples\",\n",
    "            \"class_weight\",\n",
    "            \"bootstrap\",\n",
    "        ]\n",
    "        if c in history_df.columns\n",
    "    ]\n",
    "    top = history_df.sort_values(\"avg_precision\", ascending=False).head(top_n)\n",
    "    display(top[cols])\n",
    "\n",
    "    if \"stage\" in history_df.columns:\n",
    "        print(\"\\nBest AP by stage:\")\n",
    "        display(\n",
    "            history_df.groupby(\"stage\")[\"avg_precision\"]\n",
    "            .max()\n",
    "            .rename(\"best_avg_precision\")\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "\n",
    "OUT_DIR: str | Path = \"../artifacts/rf_successive_halving_group1\"\n",
    "run_name: str = \"successive_halving_W25_H5_c30_sched50-150-400\"\n",
    "sh_hist_loaded = load_search_history(OUT_DIR, run_name)\n",
    "show_top_results(sh_hist_loaded, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a68e34-0e41-4c05-96ac-75b3202dd53a",
   "metadata": {},
   "source": [
    "After an initial broad random search and a refined search, further optimization produces only minimal changes in validation AP. I will choose the final model from the top configurations based on which one has the best scores over multiple different random states (seeds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99a06001-6271-4b76-a315-6b8c3373e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_over_seeds(\n",
    "    params: dict,\n",
    "    n_estimators: int,\n",
    "    seeds: list[int],\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    X_val,\n",
    "    y_val,\n",
    "):\n",
    "    aps = []\n",
    "    for s in seeds:\n",
    "        print(f\"Fitting seed {s}\")\n",
    "        model = RandomForestClassifier(\n",
    "            **params,\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=s,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        model.fit(X_tr, y_tr)\n",
    "        ap = average_precision_score(y_val, model.predict_proba(X_val)[:, 1])\n",
    "        aps.append(float(ap))\n",
    "\n",
    "    return float(np.mean(aps)), float(np.std(aps)), aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1caeda6a-33bb-4d51-8990-857216b72b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_avg_precision</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_ap</th>\n",
       "      <th>std_ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.668961</td>\n",
       "      <td>400</td>\n",
       "      <td>0.669783</td>\n",
       "      <td>0.001635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663724</td>\n",
       "      <td>400</td>\n",
       "      <td>0.665585</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.667434</td>\n",
       "      <td>400</td>\n",
       "      <td>0.659493</td>\n",
       "      <td>0.005404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.660921</td>\n",
       "      <td>400</td>\n",
       "      <td>0.653307</td>\n",
       "      <td>0.006096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orig_avg_precision  n_estimators   mean_ap    std_ap\n",
       "0            0.668961           400  0.669783  0.001635\n",
       "1            0.663724           400  0.665585  0.003064\n",
       "2            0.667434           400  0.659493  0.005404\n",
       "3            0.660921           400  0.653307  0.006096"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best by mean_ap:\n",
      "{'orig_avg_precision': np.float64(0.6689614422037214), 'n_estimators': np.int64(400), 'mean_ap': np.float64(0.6697833227880404), 'std_ap': np.float64(0.0016353255395577)}\n",
      "params: {'bootstrap': True, 'class_weight': 'balanced_subsample', 'max_depth': 14, 'max_features': 0.7, 'max_samples': 0.5, 'min_samples_leaf': 10, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "# Seed robustness check implementation, takes a while to compute.\n",
    "\n",
    "# def row_to_params(row: pd.Series) -> tuple[dict, int]:\n",
    "#     n_estimators = int(row[\"n_estimators\"])\n",
    "\n",
    "#     max_depth = row.get(\"max_depth\", None)\n",
    "#     if pd.isna(max_depth):\n",
    "#         max_depth = None\n",
    "#     else:\n",
    "#         max_depth = int(max_depth)\n",
    "\n",
    "#     params = {\n",
    "#         \"max_depth\": max_depth,\n",
    "#         \"min_samples_leaf\": int(row[\"min_samples_leaf\"]),\n",
    "#         \"min_samples_split\": int(row[\"min_samples_split\"]),\n",
    "#         \"max_features\": row[\"max_features\"],\n",
    "#         \"bootstrap\": bool(row[\"bootstrap\"]),\n",
    "#         \"max_samples\": float(row[\"max_samples\"]),\n",
    "#         \"class_weight\": row[\"class_weight\"],\n",
    "#     }\n",
    "\n",
    "#     if isinstance(params[\"max_features\"], str) and params[\"max_features\"] != \"sqrt\":\n",
    "#         params[\"max_features\"] = float(params[\"max_features\"])\n",
    "\n",
    "#     return params, n_estimators\n",
    "\n",
    "# def select_best_by_seed_robustness(\n",
    "#     history_df: pd.DataFrame,\n",
    "#     X_tr,\n",
    "#     y_tr,\n",
    "#     X_val,\n",
    "#     y_val,\n",
    "#     top_k: int = 5,\n",
    "#     seeds: list[int] | None = None,\n",
    "#     stage: int | None = None,\n",
    "# ):\n",
    "#     if seeds is None:\n",
    "#         seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "#     df = history_df.copy()\n",
    "\n",
    "#     if stage is not None and \"stage\" in df.columns:\n",
    "#         df = df[df[\"stage\"] == stage].copy()\n",
    "\n",
    "#     df = df.sort_values(\"avg_precision\", ascending=False).head(top_k)\n",
    "\n",
    "#     rows = []\n",
    "#     for _, r in df.iterrows():\n",
    "#         params, n_estimators = row_to_params(r)\n",
    "#         print(params)\n",
    "#         mean_ap, std_ap, aps = ap_over_seeds(\n",
    "#             params=params,\n",
    "#             n_estimators=n_estimators,\n",
    "#             seeds=seeds,\n",
    "#             X_tr=X_tr,\n",
    "#             y_tr=y_tr,\n",
    "#             X_val=X_val,\n",
    "#             y_val=y_val,\n",
    "#         )\n",
    "#         rows.append(\n",
    "#             {\n",
    "#                 \"orig_avg_precision\": float(r[\"avg_precision\"]),\n",
    "#                 \"n_estimators\": n_estimators,\n",
    "#                 \"mean_ap\": mean_ap,\n",
    "#                 \"std_ap\": std_ap,\n",
    "#                 \"aps\": aps,\n",
    "#                 \"params\": params,\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#     out = pd.DataFrame(rows).sort_values(\"mean_ap\", ascending=False).reset_index(\n",
    "#         drop=True\n",
    "#     )\n",
    "#     return out\n",
    "\n",
    "\n",
    "# W = 25\n",
    "# H = 5\n",
    "# X_tr, y_tr, X_val, y_val, X_te, y_te, _ = build_pooled_train_val_test(\n",
    "#     machines_dict=machines,\n",
    "#     window_size=W,\n",
    "#     horizon=H,\n",
    "#     train_frac=0.70,\n",
    "#     val_frac_within_train=0.20,\n",
    "# )\n",
    "\n",
    "# print(\"Validation positive rate:\", y_val.mean())\n",
    "\n",
    "# robust_df = select_best_by_seed_robustness(\n",
    "#     history_df=sh_hist,  # from successive halving\n",
    "#     X_tr=X_tr,\n",
    "#     y_tr=y_tr,\n",
    "#     X_val=X_val,\n",
    "#     y_val=y_val,\n",
    "#     top_k=5,\n",
    "#     seeds=[0, 10, 100, 500, 2026],\n",
    "#     stage=3,  # final stage\n",
    "# )\n",
    "\n",
    "# display(robust_df[[\"orig_avg_precision\", \"n_estimators\", \"mean_ap\", \"std_ap\", \"aps\"]])\n",
    "# best_choice = robust_df.iloc[0]\n",
    "# best_choice[\"params\"], best_choice[\"n_estimators\"], best_choice[\"mean_ap\"]\n",
    "\n",
    "\n",
    "# I ran the search and saved the results\n",
    "# Instead of repeating the search above, load the saved search history and analyze results:\n",
    "def load_robustness_df(\n",
    "    out_dir: str | Path = \"../artifacts/rf_seed_check_group1\",\n",
    "    run_name: str = \"seed_robustness_W25_H5\",\n",
    ") -> pd.DataFrame:\n",
    "    out_dir = Path(out_dir)\n",
    "    parquet_path = out_dir / f\"{run_name}.parquet\"\n",
    "    csv_path = out_dir / f\"{run_name}.csv\"\n",
    "\n",
    "    if parquet_path.exists():\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "    elif csv_path.exists():\n",
    "        df = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Missing {parquet_path} and {csv_path}\")\n",
    "\n",
    "    if \"params_json\" in df.columns:\n",
    "        df[\"params\"] = df[\"params_json\"].apply(\n",
    "            lambda s: json.loads(s) if pd.notna(s) else None\n",
    "        )\n",
    "        df = df.drop(columns=[\"params_json\"])\n",
    "\n",
    "    if \"aps_json\" in df.columns:\n",
    "        df[\"aps\"] = df[\"aps_json\"].apply(\n",
    "            lambda s: json.loads(s) if pd.notna(s) else None\n",
    "        )\n",
    "        df = df.drop(columns=[\"aps_json\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_robustness_summary(df: pd.DataFrame):\n",
    "    cols = [c for c in [\"orig_avg_precision\", \"n_estimators\", \"mean_ap\", \"std_ap\"] if c in df.columns]\n",
    "    display(df.sort_values(\"mean_ap\", ascending=False)[cols])\n",
    "\n",
    "    best = df.sort_values(\"mean_ap\", ascending=False).iloc[0]\n",
    "    print(\"\\nBest by mean_ap:\")\n",
    "    print({k: best[k] for k in cols if k in best.index})\n",
    "    if \"params\" in df.columns:\n",
    "        print(\"params:\", best[\"params\"])\n",
    "\n",
    "robust_df_loaded = load_robustness_df(\n",
    "    out_dir=\"../artifacts/rf_seed_check_group1\",\n",
    "    run_name=\"seed_robustness_W25_H5\",\n",
    ")\n",
    "\n",
    "print_robustness_summary(robust_df_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b7c6251-3fa8-40a4-ad4e-88e10317262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final model to: ../artifacts/final_rf_group1/rf_final_W25_H5.joblib\n",
      "Saved metadata to: ../artifacts/final_rf_group1/rf_final_W25_H5.json\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Use the chosen robust params from above\n",
    "final_params = robust_df_loaded.sort_values(\"mean_ap\", ascending=False).iloc[0][\"params\"]\n",
    "n_estimators_tuned = int(robust_df_loaded.sort_values(\"mean_ap\", ascending=False).iloc[0][\"n_estimators\"])\n",
    "\n",
    "# Increase trees for final fit (stabilizes probabilities)\n",
    "# Rule of thumb: 2x–5x the tuned value; keep compute reasonable\n",
    "n_estimators_final = max(800, 2 * n_estimators_tuned)\n",
    "\n",
    "W = 25\n",
    "H = 5\n",
    "X_tr, y_tr, X_val, y_val, X_te, y_te, _ = build_pooled_train_val_test(\n",
    "    machines_dict=machines,\n",
    "    window_size=W,\n",
    "    horizon=H,\n",
    "    train_frac=0.70,\n",
    "    val_frac_within_train=0.20,\n",
    ")\n",
    "\n",
    "X_trainval = np.concatenate([X_tr, X_val], axis=0)\n",
    "y_trainval = np.concatenate([y_tr, y_val], axis=0)\n",
    "\n",
    "final_model = RandomForestClassifier(\n",
    "    **final_params,\n",
    "    n_estimators=n_estimators_final,\n",
    "    random_state=2026,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "final_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "ART_DIR = Path(\"../artifacts/final_rf_group1\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = ART_DIR / f\"rf_final_W{W}_H{H}.joblib\"\n",
    "dump(final_model, model_path)\n",
    "\n",
    "meta = {\n",
    "    \"W\": W,\n",
    "    \"H\": H,\n",
    "    \"train_frac\": 0.70,\n",
    "    \"val_frac_within_train\": 0.20,\n",
    "    \"purge_gap\": W + H,\n",
    "    \"n_estimators_tuned\": n_estimators_tuned,\n",
    "    \"n_estimators_final\": n_estimators_final,\n",
    "    \"params\": final_params,\n",
    "    \"val_pos_rate\": float(y_val.mean()),\n",
    "}\n",
    "\n",
    "meta_path = ART_DIR / f\"rf_final_W{W}_H{H}.json\"\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved final model to:\", model_path)\n",
    "print(\"Saved metadata to:\", meta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc913f-ed61-47fd-9f98-1204543bc2e3",
   "metadata": {},
   "source": [
    "### Final Model Choice (W = 25) via Seed Robustness Check\n",
    "\n",
    "To reduce the risk of selecting a configuration that is “lucky” due to Random Forest randomness\n",
    "(bootstrapping / feature subsampling), I evaluated the top candidate configurations across multiple\n",
    "random seeds on the validation set.\n",
    "\n",
    "The best candidate achieved mean validation AP ≈ 0.669 with std ≈ 0.001 across 5 seeds, indicating\n",
    "high stability. I select this configuration as the final W=25 model and proceed to refit it on the\n",
    "combined train+validation data before final evaluation on the held-out test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc8286-ad1e-4268-a944-4916450e98fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
