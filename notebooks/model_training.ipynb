{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d86a6d-5ea3-4707-bd7e-c4fe34df5e15",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "The work in this notebook focuses on the problem formulation and model selection, training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920deb72-cff9-4bff-9509-550ae57aae0a",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "\n",
    "In this section I work out the sliding window and prediction horizon. Since I couldn't find any mentions of recording frequency for this dataset, I will work with the assumption that the data has been recorded in 1-minute intervals. The exact unknown time intervals aren't as important, the interpretation serves mostly for the readability and ease of understanding of this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3facde0b-0bea-4014-9b62-4845de424be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9baf7f-d52f-4946-b04f-cbfd1d5d02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train_clean.csv')\n",
    "test_df = pd.read_csv('../data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607ff04-c99a-4649-a520-eb387ccd0745",
   "metadata": {},
   "source": [
    "### Prediction Horizon H\n",
    "\n",
    "Determining the size of H presents a trade-off:\n",
    "- Large (e.g. 60 min) is great for operators, because they get a lot of time to fix the issue, but the prediction accuracy drops significantly. It is very hard to predict a crash 1 hour in advance from minute-level metrics.\n",
    "- Small (e.g. 1 min): has high prediction accuracy, but useless for operations. By the time the alert fires, the server is already dead.\n",
    "\n",
    "For this project, I set the value of H to 5 minutes. This is the standard SLA reaction time. It should give operators enough time to react to the incident."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b563be3-7130-4913-a4f0-1740011b8e1d",
   "metadata": {},
   "source": [
    "### Sliding Window W\n",
    "\n",
    "This parameter also presents a trade-off:\n",
    "- Small W (e.g. 1-2 min): The model only sees the current spike, it cannot detect longer trends.\n",
    "- Large W (e.g. 60+ min): The model has a clear picture of ongoing changes, but these can also be irrelevant or misleading.\n",
    "\n",
    "When it comes to cloud infrastructure failures, they can appear in short time (Shock failures) but also over longer time, say 10-20 minutes. Selecting an exact amount can be tricky, so in this project, I will implement two different values for W, train models for both of them and compare results at the end. The two values I chose are:\n",
    "- 12 minutes: should be long enough to capture some longer trends while maintaining noise resistance.\n",
    "- 25 minutes: sees further back. Could catch a slower trend that W = 12 misses, but might also get diluted with noise.\n",
    "\n",
    "For this purpose, I implement the function below, that:\n",
    "1. Slides a window of size 'W' over the data.\n",
    "2. Calculates rolling stats (Mean, Std, Delta, Z-Score) for that window.\n",
    "3. Checks the next 'H' steps to define the Label (1 if crash, 0 if safe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e50308bd-dad7-4006-8e90-ae13a74dd690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_supervised_dataset(data_df, labels, window_size, horizon):\n",
    "    \n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    if 'label' in data_df.columns:\n",
    "        feature_data = data_df.drop(columns=['label']).values\n",
    "    else:\n",
    "        feature_data = data_df.values\n",
    "        \n",
    "    labels = labels.values\n",
    "    \n",
    "    print(f\"Generating features (W={window_size}, H={horizon})...\")\n",
    "    \n",
    "    for t in range(window_size, len(feature_data) - horizon):\n",
    "        \n",
    "        # The Input Window \n",
    "        window = feature_data[t-window_size : t]\n",
    "        \n",
    "        # Calculate stats for every feature\n",
    "        w_mean = np.mean(window, axis=0)\n",
    "        w_std  = np.std(window, axis=0)\n",
    "        \n",
    "        # The change between the very last point and the one before it\n",
    "        w_delta = window[-1] - window[-2]\n",
    "        \n",
    "        # The last point relative to the window's stats\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            w_zscore = (window[-1] - w_mean) / w_std\n",
    "        w_zscore = np.nan_to_num(w_zscore) \n",
    "        \n",
    "        # Combine all stats into one long vector for this row\n",
    "        features_vector = np.concatenate([w_mean, w_std, w_delta, w_zscore])\n",
    "        \n",
    "        # The Target Window\n",
    "        future_window = labels[t : t+horizon]\n",
    "        \n",
    "        # If an anomaly happens in the future window, label = 1\n",
    "        is_crash = 1 if np.sum(future_window) > 0 else 0\n",
    "        \n",
    "        X_list.append(features_vector)\n",
    "        y_list.append(is_crash)\n",
    "        \n",
    "    return np.array(X_list), np.array(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215fb121-66ba-4f6d-9996-267c4e92ce54",
   "metadata": {},
   "source": [
    "Next, I create the two proposed datasets with the two values for W. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61043c3-09dd-4b9f-8289-41914b53f5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Training Sets ---\n",
      "Generating features (W=12, H=5)...\n",
      "Generating features (W=25, H=5)...\n",
      "\n",
      "--- Creating Test Sets ---\n",
      "Generating features (W=12, H=5)...\n",
      "Generating features (W=25, H=5)...\n",
      "\n",
      "--- Shape Verification ---\n",
      "Short Window (W=12): (19918, 124) features per row\n",
      "Long Window  (W=25): (19905, 124) features per row\n"
     ]
    }
   ],
   "source": [
    "H = 5\n",
    "W_short = 12\n",
    "W_long = 25\n",
    "\n",
    "# Prepare Training Data\n",
    "print(\"--- Creating Training Sets ---\")\n",
    "X_train_short, y_train_short = create_supervised_dataset(train_df, train_df['label'], W_short, H)\n",
    "X_train_long,  y_train_long  = create_supervised_dataset(train_df, train_df['label'], W_long, H)\n",
    "\n",
    "# Prepare Test Data\n",
    "print(\"\\n--- Creating Test Sets ---\")\n",
    "X_test_short, y_test_short = create_supervised_dataset(test_df, test_df['label'], W_short, H)\n",
    "X_test_long,  y_test_long  = create_supervised_dataset(test_df, test_df['label'], W_long, H)\n",
    "\n",
    "# Validation\n",
    "print(\"\\n--- Shape Verification ---\")\n",
    "print(f\"Short Window (W=12): {X_train_short.shape} features per row\")\n",
    "print(f\"Long Window  (W=25): {X_train_long.shape} features per row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4276bf7-e3a1-4bfe-a0a7-e36469cc3d68",
   "metadata": {},
   "source": [
    "## Model Selection and Training\n",
    "\n",
    "Based on information observed during EDA as well as the nature of the problem, I have chosen **Random Forest Classifier** for this task. \n",
    "The main reasons are:\n",
    "1. **Non-Linear features:** In the bivariate analysis, I observed that some features (like feat_8 or feat_29) remain at 0.0 for long periods and spike suddenly during an incident. Linear models like Logistic Regression struggle to model these sharp cliffs. Decision Trees naturally model these non-linear thresholds.\n",
    "2. **Interaction Effects:** Some features (like feat_15 or feat_22) appeared stable but are likely informative when combined with other indicators. Random Forests automatically learn these interaction effects without requiring manual feature combination.\n",
    "3. **Robustness to Noise:** The cloud metrics contain jitter and spikes that are not incidents. By averaging the predictions of multiple trees, the Random Forest reduces the variance and is less likely to overfit to individual noisy data points compared to a single Decision Tree.\n",
    "4. **Efficiency for Retraining:** The project description requires a system capable of periodic retraining. Random Forests parallelize training easily and are significantly faster and cheaper to train than recurrent neural networks.\n",
    "\n",
    "\n",
    "### Training Strategy\n",
    "\n",
    "I will train two separate models to compare the impact of the window size:\n",
    "1. Model A: Trained on \\(W=12\\)\n",
    "2. Model B: Trained on \\(W=25\\)\n",
    "\n",
    "As noted in the data analysis, the anomaly rate is approximately 10%. To ensure the model focuses on capturing incidents (Recall) rather than just maximizing accuracy, I will use class_weight='balanced'. This penalizes the model more heavily for missing a crash than for raising a false alarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e747ca-7813-49fb-88b3-114beea1063b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
